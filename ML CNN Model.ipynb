{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Input, InputLayer, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train_data_dir = 'C:/Users/arnab/OneDrive/Desktop/archive/data/train/malignant/'\n",
    "b_train_data_dir = 'C:/Users/arnab/OneDrive/Desktop/archive/data/train/benign/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'C:/Users/arnab/OneDrive/Desktop/archive/data/train/malignant/10.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(m_train_data_dir):\n\u001b[0;32m      4\u001b[0m     m_label_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(m_train_data_dir, label)\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(m_label_dir):\n\u001b[0;32m      6\u001b[0m         m_train_filenames\u001b[39m.\u001b[39mappend(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(m_label_dir, filename))\n\u001b[0;32m      7\u001b[0m         m_train_labels\u001b[39m.\u001b[39mappend(label)\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'C:/Users/arnab/OneDrive/Desktop/archive/data/train/malignant/10.jpg'"
     ]
    }
   ],
   "source": [
    "m_train_filenames = []\n",
    "m_train_labels = []\n",
    "for label in os.listdir(m_train_data_dir):\n",
    "    m_label_dir = os.path.join(m_train_data_dir, label)\n",
    "    for filename in os.listdir(m_label_dir):\n",
    "        m_train_filenames.append(os.path.join(m_label_dir, filename))\n",
    "        m_train_labels.append(label)\n",
    "\n",
    "b_train_filenames = []\n",
    "b_train_labels = []\n",
    "for label in os.listdir(b_data_dir):\n",
    "    b_label_dir = os.path.join(b_data_dir, label)\n",
    "    for filename in os.listdir(b_label_dir):\n",
    "        b_train_filenames.append(os.path.join(b_label_dir, filename))\n",
    "        b_train_labels.append(label)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m combined \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(m_train_filenames, m_train_labels))\n\u001b[0;32m      2\u001b[0m random\u001b[39m.\u001b[39mshuffle(combined)\n\u001b[1;32m----> 3\u001b[0m m_train_filenames[:], m_train_labels[:] \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mcombined)\n\u001b[0;32m      4\u001b[0m combined \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(b_train_filenames, b_train_labels))\n\u001b[0;32m      5\u001b[0m random\u001b[39m.\u001b[39mshuffle(combined)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "combined = list(zip(m_train_filenames, m_train_labels))\n",
    "random.shuffle(combined)\n",
    "m_train_filenames[:], m_train_labels[:] = zip(*combined)\n",
    "combined = list(zip(b_train_filenames, b_train_labels))\n",
    "random.shuffle(combined)\n",
    "b_train_filenames[:], b_train_labels[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 224\n",
    "input_height = 224\n",
    "input_channels = 1\n",
    "input_pixels = 224*224\n",
    "\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "conv1_k = 5\n",
    "conv2_k = 5\n",
    "max_pool1_k = 2\n",
    "max_pool2_k = 2\n",
    "\n",
    "n_hidden = 1024\n",
    "n_out = 10\n",
    "\n",
    "input_size_to_hidden = (input_width//(max_pool1_k*max_pool2_k)) * (input_height//(max_pool1_k*max_pool2_k)) *n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'random_normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m weights \u001b[39m=\u001b[39m {\n\u001b[1;32m----> 2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwc1\u001b[39m\u001b[39m\"\u001b[39m : tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39;49mrandom_normal([conv1_k, conv1_k, input_channels, n_conv1])),\n\u001b[0;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwc2\u001b[39m\u001b[39m\"\u001b[39m : tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom_normal([conv2_k, conv2_k, n_conv1, n_conv2])),\n\u001b[0;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwh1\u001b[39m\u001b[39m\"\u001b[39m : tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom_normal([input_size_to_hidden, n_hidden])),\n\u001b[0;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwo\u001b[39m\u001b[39m\"\u001b[39m : tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom_normal([n_hidden, n_out]))\n\u001b[0;32m      6\u001b[0m }\n\u001b[0;32m      8\u001b[0m biases \u001b[39m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbc1\u001b[39m\u001b[39m\"\u001b[39m : tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom_normal([n_conv1])),\n\u001b[0;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbc2\u001b[39m\u001b[39m\"\u001b[39m : tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom_normal([n_conv2])),\n\u001b[0;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbh1\u001b[39m\u001b[39m\"\u001b[39m : tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom_normal([n_hidden])),\n\u001b[0;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbo\u001b[39m\u001b[39m\"\u001b[39m : tf\u001b[39m.\u001b[39mVariable(tf\u001b[39m.\u001b[39mrandom_normal([n_out])),\n\u001b[0;32m     13\u001b[0m }\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'random_normal'"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    \"wc1\" : tf.Variable(tf.random_normal([conv1_k, conv1_k, input_channels, n_conv1])),\n",
    "    \"wc2\" : tf.Variable(tf.random_normal([conv2_k, conv2_k, n_conv1, n_conv2])),\n",
    "    \"wh1\" : tf.Variable(tf.random_normal([input_size_to_hidden, n_hidden])),\n",
    "    \"wo\" : tf.Variable(tf.random_normal([n_hidden, n_out]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\" : tf.Variable(tf.random_normal([n_conv1])),\n",
    "    \"bc2\" : tf.Variable(tf.random_normal([n_conv2])),\n",
    "    \"bh1\" : tf.Variable(tf.random_normal([n_hidden])),\n",
    "    \"bo\" : tf.Variable(tf.random_normal([n_out])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, input_pixels])\n",
    "y = tf.placeholder(tf.int32, [None, n_out])\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "pred = cnn(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(mnist.train.num_examples/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost,optimize], feed_dict={x:batch_x , y:batch_y, keep_prob:0.8})\n",
    "        total_cost += c\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.argmax(pred, 1)\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "predictions,correct_preds  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels, keep_prob:1.0})\n",
    "correct_preds.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
